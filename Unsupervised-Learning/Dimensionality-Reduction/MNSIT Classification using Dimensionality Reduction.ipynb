{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim:\n",
    "\n",
    "Load the MNIST dataset and split it into a training set\n",
    "and a test set. Train a Random Forest classifier on the dataset and time how\n",
    "long it takes, then evaluate the resulting model on the test set. \n",
    "\n",
    "\n",
    "Next, use different dimensionality reduction techniques to\n",
    "reduce the datasetâ€™s dimensionality.\n",
    "Train a new Random Forest classifier on the reduced dataset and see how long it\n",
    "takes. Was training much faster? Next, evaluate the classifier on the test set. How\n",
    "does it compare to the previous classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Importing MNIST dataset\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.target = mnist.target.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training features: (56000, 784)\n",
      "Shape of training labels: (56000,)\n",
      "Shape of testing features: (14000, 784)\n",
      "Shape of testing labels: (14000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training features:\",X_train.shape)\n",
    "print(\"Shape of training labels:\",y_train.shape)\n",
    "print(\"Shape of testing features:\",X_test.shape)\n",
    "print(\"Shape of testing labels:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF without dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for RF without dimensionality reduction is: 0.9668587063036626\n",
      "Training took 43.13s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "\n",
    "RF=RandomForestClassifier(random_state=123)\n",
    "t0 = time.time()\n",
    "RF.fit(X_train,y_train)\n",
    "t1 = time.time()\n",
    "\n",
    "RF_score=cross_val_score(RF,X_train,y_train,scoring='f1_macro',cv=5)\n",
    "print(\"F1 score for RF without dimensionality reduction is:\",RF_score.mean())\n",
    "print(\"Training took {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduction with PCA took 93.56s\n",
      "F1 score for RF with PCA is: 0.944492061782839\n",
      "Training took 93.56s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#PCA with an explained variance ratio of 95%\n",
    "pca = PCA(n_components=0.95,random_state=123)\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "RF=RandomForestClassifier(random_state=123)\n",
    "t0 = time.time()\n",
    "RF.fit(X_train_reduced,y_train)\n",
    "t1 = time.time()\n",
    "print(\"Reduction with PCA took {:.2f}s\".format(t1 - t0))\n",
    "\n",
    "RF_score=cross_val_score(RF,X_train_reduced,y_train,scoring='f1_macro',cv=5)\n",
    "print(\"F1 score for RF with PCA is:\",RF_score.mean())\n",
    "print(\"Training took {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features reduced from 784 to 154 but training is actually more than twice slower now! How can that be? Well, dimensionality reduction does not always lead to faster training time: it depends on the dataset, the model and the training algorithm. If you try a softmax classifier (multi class logisitic regression) instead of a random forest classifier, you will find that training time is reduced by a factor of 3 when using PCA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe measure of goodness of fit in multidimensional scaling is called S(caled)-Stress!\\nStress varies between 0 and 1, with values near 0 indicating better fit.\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The measure of goodness of fit in multidimensional scaling is called S(caled)-Stress!\n",
    "Stress varies between 0 and 1, with values near 0 indicating better fit.\n",
    "PCA is equivalent to classical MDS using the Euclidean distance metric. \n",
    "So, if this is the type of MDS you want to perform, you can use PCA instead. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWe will not be implementing IsoMap as it is computationally expensive(source:https://www.cs.ubc.ca/~tmm/courses/533-07/slides/hidim.donovan-4x4.pdf)\\nfrom sklearn import manifold \\nt0 = time.time()\\nX_train_reduced = manifold.Isomap().fit_transform(X_train)\\nt1 = time.time()\\nprint(\"Reduction with Isomap took {:.2f}s\".format(t1 - t0))\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will not be implementing IsoMap as it is computationally expensive(source:https://www.cs.ubc.ca/~tmm/courses/533-07/slides/hidim.donovan-4x4.pdf)\n",
    "from sklearn import manifold \n",
    "t0 = time.time()\n",
    "X_train_reduced = manifold.Isomap().fit_transform(X_train)\n",
    "t1 = time.time()\n",
    "print(\"Reduction with Isomap took {:.2f}s\".format(t1 - t0))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduction with t-SNE took 8783.98s\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "t-SNE is used mostly for visualization\n",
    "ValueError: 'n_components' should be inferior to 4 for the barnes_hut algorithm as it relies on quad-tree or oct-tree.\n",
    "\"\"\"\n",
    "from sklearn.manifold import TSNE\n",
    "t0 = time.time()\n",
    "X_train_reduced_SNE = TSNE().fit_transform(X_train)\n",
    "t1 = time.time()\n",
    "print(\"Reduction with t-SNE took {:.2f}s\".format(t1 - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for RF with t-SNE is: 0.9712626232902455\n",
      "Training took 19.05s\n"
     ]
    }
   ],
   "source": [
    "RF_SNE=RandomForestClassifier(random_state=123)\n",
    "t0 = time.time()\n",
    "RF_SNE.fit(X_train_reduced_SNE,y_train)\n",
    "t1 = time.time()\n",
    "\n",
    "\n",
    "RF_score=cross_val_score(RF_SNE,X_train_reduced_SNE,y_train,scoring='f1_macro',cv=5)\n",
    "print(\"F1 score for RF with t-SNE is:\",RF_score.mean())\n",
    "print(\"Training took {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduction with UMAP took 142.10s\n"
     ]
    }
   ],
   "source": [
    "import umap\n",
    "t0 = time.time()\n",
    "um=umap.UMAP(random_state=123)\n",
    "X_train_reduced = um.fit_transform(X_train)\n",
    "t1 = time.time()\n",
    "print(\"Reduction with UMAP took {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for RF with UMAP is: 0.9641087867528005\n",
      "Training took 19.95s\n"
     ]
    }
   ],
   "source": [
    "RF=RandomForestClassifier(random_state=123)\n",
    "t0 = time.time()\n",
    "RF.fit(X_train_reduced,y_train)\n",
    "t1 = time.time()\n",
    "\n",
    "\n",
    "RF_score=cross_val_score(RF,X_train_reduced,y_train,scoring='f1_macro',cv=5)\n",
    "print(\"F1 score for RF with UMAP is:\",RF_score.mean())\n",
    "print(\"Training took {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though t-SNE took the longest to train, we got a high F1 score. We will use the model trained by UMAP it took the least to train and still gave a high result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for test set is: 0.9580496682877884\n",
      "Accuracy score for test set is: 0.9582857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1358\n",
      "           1       0.95      0.99      0.97      1596\n",
      "           2       0.98      0.93      0.95      1403\n",
      "           3       0.95      0.96      0.95      1450\n",
      "           4       0.98      0.94      0.96      1327\n",
      "           5       0.94      0.94      0.94      1249\n",
      "           6       0.97      0.98      0.98      1367\n",
      "           7       0.96      0.96      0.96      1459\n",
      "           8       0.96      0.92      0.94      1413\n",
      "           9       0.93      0.96      0.94      1378\n",
      "\n",
      "    accuracy                           0.96     14000\n",
      "   macro avg       0.96      0.96      0.96     14000\n",
      "weighted avg       0.96      0.96      0.96     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#tranforming testing features\n",
    "X_test_reduced_umap = um.transform(X_test)\n",
    "\n",
    "yhat=RF.predict(X_test_reduced_umap)\n",
    "print(\"F1 score for test set is:\",f1_score(y_test,yhat,average='macro'))\n",
    "print(\"Accuracy score for test set is:\",accuracy_score(y_test,yhat))\n",
    "print(classification_report(y_test,yhat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
